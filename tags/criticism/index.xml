<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>criticism on HeroLFG</title>
    <link>https://herolfg.com/tags/criticism/</link>
    <description>Recent content in criticism on HeroLFG</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Aug 2022 04:23:08 -0500</lastBuildDate><atom:link href="https://herolfg.com/tags/criticism/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Effective Altruism Criticisms</title>
      <link>https://herolfg.com/posts/effective-altruism-criticism/</link>
      <pubDate>Thu, 11 Aug 2022 04:23:08 -0500</pubDate>
      
      <guid>https://herolfg.com/posts/effective-altruism-criticism/</guid>
      <description>I recently learned about the Effective Altruism (EA) organization who has a competition with incentives for people to help with their error correction. The strategy of a competition and the goal of doing error correction is praiseworthy.
My criticisms are generally related to attention and technology because I believe attention is the most valuable resource in the world and technology can help us manage our attention better.
Criticism: EA Transparency Technology How good is the judging process for this competition?</description>
    </item>
    
  </channel>
</rss>
